{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Programming Task: Digit recognition using CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T13:21:14.125709952Z",
     "start_time": "2024-01-10T13:21:14.070486433Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Complete the code for the ConvNet class given below using the network description from supplement pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T13:21:14.142366557Z",
     "start_time": "2024-01-10T13:21:14.104414427Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 20, 5, 1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(20 * 12 * 12, 100),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.pred = nn.Linear(100, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        x = self.pred(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T13:21:14.156473624Z",
     "start_time": "2024-01-10T13:21:14.132942945Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=2880, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (pred): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = ConvNet()\n",
    "print(net)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. Train the CNN and observe the difference in performance in comparison to the feed-forward\n",
    "network from the task 5.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T13:21:14.167383515Z",
     "start_time": "2024-01-10T13:21:14.147212836Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set hyper parameters.\n",
    "lr = 0.001\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T13:21:14.468189283Z",
     "start_time": "2024-01-10T13:21:14.156743062Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the MNIST data set.\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "train_loader = Data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = Data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T13:21:14.475859630Z",
     "start_time": "2024-01-10T13:21:14.254226362Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the loss function and the optimization criteria\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T13:21:37.202416384Z",
     "start_time": "2024-01-10T13:21:14.254384036Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/5]: 100%|██████████| 600/600 [00:04<00:00, 125.56it/s, loss=0.0752]\n",
      "Epoch [2/5]: 100%|██████████| 600/600 [00:04<00:00, 130.90it/s, loss=0.039]  \n",
      "Epoch [3/5]: 100%|██████████| 600/600 [00:04<00:00, 135.23it/s, loss=0.0331] \n",
      "Epoch [4/5]: 100%|██████████| 600/600 [00:04<00:00, 130.70it/s, loss=0.0344] \n",
      "Epoch [5/5]: 100%|██████████| 600/600 [00:04<00:00, 131.83it/s, loss=0.0592] \n"
     ]
    }
   ],
   "source": [
    "# Run the main training loop\n",
    "def train(model, dataloader, loss_fn, optimizer, num_epochs=10, device='cpu'):\n",
    "    model.train()\n",
    "    for i in range(num_epochs):\n",
    "        loop = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "        for batch_idx, (data, target) in loop:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loop.set_description(f'Epoch [{i+1}/{num_epochs}]')\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "            \n",
    "            \n",
    "train(net, train_loader, loss_fn, optimizer, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T13:28:18.834328197Z",
     "start_time": "2024-01-10T13:28:18.102858597Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 100/100 [00:00<00:00, 145.18it/s, accuracy=98.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 9880 / 10000 with accuracy 98.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the testing loop\n",
    "def test(model, dataloader, device='cpu'):\n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    loop = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in loop:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, predictions = output.max(1)\n",
    "            num_correct += (predictions == target).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "            loop.set_description(f'Testing')\n",
    "            loop.set_postfix(accuracy=(float(num_correct)/float(num_samples))*100)\n",
    "    print(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')\n",
    "    \n",
    "\n",
    "test(net, test_loader, device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. Calculate the number of learnable parameters and the output shape in each layer. Verify your\n",
    "answers with model summary. (Refer last cell of the tutorial notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T13:44:03.929240463Z",
     "start_time": "2024-01-10T13:44:03.920355589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolutional layer parameters: 520\n",
      "Covolutional layer output shape: (20, 24.0, 24.0)\n",
      "MaxPool2d output shape: (20, 12.0, 12.0)\n",
      "Fully connected layer parameters: 288100\n",
      "Fully connected layer output shape: 100\n",
      "Final layer parameters: 1010\n",
      "Final layer output shape: 10\n",
      "Total number of learnable parameters: 289630\n"
     ]
    },
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nConvNet                                  [1, 10]                   --\n├─Sequential: 1-1                        [1, 20, 24, 24]           --\n│    └─Conv2d: 2-1                       [1, 20, 24, 24]           520\n│    └─ReLU: 2-2                         [1, 20, 24, 24]           --\n├─MaxPool2d: 1-2                         [1, 20, 12, 12]           --\n├─Sequential: 1-3                        [1, 100]                  --\n│    └─Linear: 2-3                       [1, 100]                  288,100\n│    └─ReLU: 2-4                         [1, 100]                  --\n├─Linear: 1-4                            [1, 10]                   1,010\n==========================================================================================\nTotal params: 289,630\nTrainable params: 289,630\nNon-trainable params: 0\nTotal mult-adds (M): 0.59\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.09\nParams size (MB): 1.16\nEstimated Total Size (MB): 1.25\n=========================================================================================="
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (1, 28, 28)\n",
    "\n",
    "# Convolutional layer weights: kernel_size * kernel_size * in_channels * out_channels + biases (out_channels)\n",
    "conv_params = 5 * 5 * 1 * 20 + 20\n",
    "# Convolutional layer output shape: (in_channels, out_channels, (input_height + 2 * padding - kernel_size) / stride + 1, (input_width + 2 * padding - kernel_size) / stride + 1)\n",
    "conv_shape = (20, (28 + 0 - 5) / 1 + 1, (28 + 0 - 5) / 1 + 1)\n",
    "\n",
    "# no params for ReLu, MaxPool2d\n",
    "# MaxPool2d output shape: (in_channels, out_channels, (input_height + 2 * padding - kernel_size) / stride + 1, (input_width + 2 * padding - kernel_size) / stride + 1)\n",
    "pool_shape = (20, (conv_shape[1] + 0 - 2) / 2 + 1, (conv_shape[2] + 0 - 2) / 2 + 1)\n",
    "\n",
    "# Fully connected layer weights: in_features * out_features + biases (out_features)\n",
    "fc_params = 20 * 12 * 12 * 100 + 100\n",
    "# Fully connected layer output shape: (out_features)\n",
    "fc_shape = (100)\n",
    "\n",
    "# final layer params: in_features * out_features + biases (out_features)\n",
    "pred_params = 100 * 10 + 10\n",
    "# final layer output shape: (out_features)\n",
    "pred_shape = (10)\n",
    "\n",
    "total_params = conv_params + fc_params + pred_params\n",
    "\n",
    "print(f'Convolutional layer parameters: {conv_params}')\n",
    "print(f'Covolutional layer output shape: {conv_shape}')\n",
    "print(f'MaxPool2d output shape: {pool_shape}')\n",
    "print(f'Fully connected layer parameters: {fc_params}')\n",
    "print(f'Fully connected layer output shape: {fc_shape}')\n",
    "print(f'Final layer parameters: {pred_params}')\n",
    "print(f'Final layer output shape: {pred_shape}')\n",
    "print(f'Total number of learnable parameters: {total_params}')\n",
    "\n",
    "summary(net, input_size=(1, 1, 28, 28))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PCDet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "7c617624a7fd88b4018bd9e75be0d58c4afb6a334791d511af9b9a5162b5af2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
